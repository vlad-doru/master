{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the data file from ./airline-twitter-sentiment/Tweets.csv\n",
      "We have 14640 labelled examples.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import pandas \n",
    "\n",
    "from lib import loading\n",
    "\n",
    "df = loading.load_data()\n",
    "print(\"We have {0} labelled examples.\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a total of 14640 tweets\n",
      "Training sample size: 13163\n",
      "Testing sample size: 1477\n"
     ]
    }
   ],
   "source": [
    "from lib import processing\n",
    "\n",
    "training_data, testing_data = processing.process_data(df, sample_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram features 1721\n",
      "Bigram features:  1203\n"
     ]
    }
   ],
   "source": [
    "from lib import classify\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "classify.add_features(training_data, sentim_analyzer)\n",
    "train, test = classify.extract_features(training_data, testing_data, sentim_analyzer)\n",
    "\n",
    "def evaluate_trainer(trainer):\n",
    "    classifier, evaluation, _ = classify.train_model(train, test, sentim_analyzer, trainer)\n",
    "    return {\n",
    "        'classifier': classifier,\n",
    "        'evaluation': evaluation,\n",
    "        'trainer': trainer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "evaluations = []\n",
    "k_range = [3, 5, 10, 15]\n",
    "for k in k_range: \n",
    "    trainer = {\n",
    "        \"name\": \"K Nearest Neighbours Classifier\",\n",
    "        \"train\": SklearnClassifier(KNeighborsClassifier(\n",
    "                n_neighbors = k,\n",
    "                n_jobs = -1,\n",
    "                weights = \"distance\")).train,\n",
    "    }\n",
    "    print(\"Training with k = \", k)\n",
    "    evaluations.append(evaluate_trainer(trainer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = [e['evaluation']['Accuracy'] for e in evaluations]\n",
    "plt.plot(k_range, accuracies)\n",
    "plt.xlabel(\"K Neighbours Parameter value\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluzie\n",
    "\n",
    "### Valoarea optima pentru cei mai apropiati  k vecini este 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: K Nearest Neighbours Classifier\n",
      "Training classifier\n",
      "Evaluating SklearnClassifier results...\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "trainer = {\n",
    "    \"name\": \"K Nearest Neighbours Classifier\",\n",
    "    \"train\": SklearnClassifier(KNeighborsClassifier(n_neighbors = k)).train,\n",
    "}\n",
    "evaluation = evaluate_trainer(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.5348679756262694, 'Precision [positive]': 0.632768361581921, 'F-measure [neutral]': 0.41923076923076924, 'Precision [neutral]': 0.29579375848032563, 'F-measure [positive]': 0.5450121654501217, 'Precision [negative]': 0.8170515097690941, 'Recall [neutral]': 0.7194719471947195, 'Recall [positive]': 0.47863247863247865, 'F-measure [negative]': 0.612109115103127, 'Recall [negative]': 0.48936170212765956}\n"
     ]
    }
   ],
   "source": [
    "print(evaluation['evaluation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
